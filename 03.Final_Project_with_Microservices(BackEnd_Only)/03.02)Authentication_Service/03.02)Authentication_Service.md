# Test-Driven Development: Authentication System - Algorithmic Guide

## **Core Development Flow**

```
TDD CYCLE:
1. Write failing test (RED)
2. Write minimal code to pass test (GREEN)
3. Refactor while tests pass (REFACTOR)
4. Repeat
```

## **1. Environment & Configuration Management**

### **Secret Management Algorithm**
```
PRODUCTION SECRETS FLOW:
→ Store sensitive data in .env file (never commit)
→ .env.example contains variable names without values
→ In production: use platform-specific secret managers
→ Access via process.env.VARIABLE_NAME

ENVIRONMENT-SPECIFIC CONFIGURATION:
Development → Local MongoDB, debug logging
Testing → In-memory MongoDB, no external services
Production → Cloud MongoDB, Redis, optimized settings
```

### **Package.json Scripts Strategy**
```
npm run test → Sequential tests (no parallel conflicts)
npm run test:watch → Watch mode for TDD cycle
npm run dev → Auto-restart with file changes

WHY --runInBand:
→ Prevents test database race conditions
→ Ensures clean state between tests
→ Maintains test execution order
```

## **2. Test Architecture Patterns**

### **Test Isolation Algorithm**
```
BEFORE EACH TEST SUITE:
→ Launch fresh in-memory MongoDB instance
→ Set unique MONGO_URI for this test run
→ Initialize clean Redis mock

AFTER EACH TEST:
→ Delete all documents from all collections
→ Reset any mock function calls
→ Clear any accumulated state

BETWEEN TESTS:
→ Never share database state
→ Each test starts with empty collections
→ Tests are order-independent
```

### **Test Data Seeding Pattern**
```
SEED FUNCTION TEMPLATE:
1. Create user with hashed password
2. Save to test database
3. Login via API to get auth cookie
4. Return { user, authCookie } for test use

REUSABLE TEST HELPERS:
→ createTestUser() - returns authenticated user
→ createTestProduct() - returns product with seller
→ createTestOrder() - returns order with status
```

## **3. Database Strategy**

### **MongoDB Connection Algorithm**
```
PRODUCTION CONNECTION:
→ Use connection pooling (max 10 connections)
→ Enable SSL/TLS for cloud databases
→ Set heartbeat frequency (30 seconds)
→ Implement reconnection logic

TEST CONNECTION:
→ In-memory MongoDB server
→ No network latency
→ Automatic cleanup
→ No persistence needed
```

### **Clever Query Patterns**
```
DUPLICATE CHECK PATTERN:
const existingUser = await User.findOne({
  $or: [
    { email: newEmail },
    { username: newUsername }
  ]
});

COMPOUND INDEX STRATEGY:
→ Index frequently queried fields together
→ Example: { email: 1, status: 1 } 
→ Test index usage with explain()
```

## **4. Authentication Flow Algorithms**

### **Token Management Algorithm**
```
JWT TOKEN LIFECYCLE:
1. CREATE: On register/login → payload + secret + expiry
2. STORE: In HTTP-only cookie (secure, sameSite: 'strict')
3. VERIFY: Middleware checks token + blacklist
4. REVOKE: Add to Redis blacklist on logout
5. EXPIRE: Automatic cleanup via Redis TTL

COOKIE CONFIGURATION:
Development → secure: false (no HTTPS locally)
Production → secure: true, sameSite: 'strict'
```

### **Redis Blacklist Strategy**
```
TOKEN BLACKLIST ALGORITHM:
Key format: `blacklist:${token}`
Value: `1` (or user ID for tracking)
TTL: Matches token expiry time

WHY USE REDIS:
→ Fast in-memory lookups
→ Automatic expiration
→ Distributed system ready
→ High throughput
```

## **5. Validation & Middleware Patterns**

### **Validation Chain Algorithm**
```
REQUEST VALIDATION FLOW:
1. Input sanitation (trim, escape)
2. Schema validation (express-validator)
3. Business logic validation (custom)
4. Database validation (unique checks)
5. Return early on first failure

VALIDATION PRIORITY:
1. Required fields → 400 Bad Request
2. Format validation → 400 Bad Request  
3. Business rules → 409 Conflict
4. Authorization → 401/403 Unauthorized
```

### **Middleware Execution Order**
```
TYPICAL MIDDLEWARE STACK:
1. CORS & Security headers
2. Request logging
3. Cookie/body parsing
4. Authentication (if required)
5. Authorization (role/permission check)
6. Validation (input sanitization)
7. Rate limiting
8. Route handler
9. Error handling
10. Response formatting
```

## **6. Testing Strategies**

### **Test Category Organization**
```
UNIT TESTS (White box):
→ Test individual functions in isolation
→ Mock all dependencies
→ Fast execution (milliseconds)

INTEGRATION TESTS (Gray box):
→ Test API endpoints with database
→ Use real services but test versions
→ Medium execution (seconds)

E2E TESTS (Black box):
→ Test complete user flows
→ Use production-like environment
→ Slow execution (minutes)
```

### **Test Data Factory Pattern**
```
FACTORY FUNCTIONS:
createUser(overrides) → returns user object
createProduct(sellerId) → returns product
createOrder(userId, items) → returns order

ADVANTAGES:
→ Consistent test data
→ Easy to modify specific fields
→ Reduces test setup duplication
```

## **7. Error Handling Strategy**

### **Error Response Algorithm**
```
STANDARD ERROR FORMAT:
{
  success: false,
  error: {
    code: 'VALIDATION_ERROR',
    message: 'Invalid email format',
    details: [ { field: 'email', issue: 'format' } ]
  }
}

HTTP STATUS MAPPING:
400 → Validation errors
401 → Authentication required
403 → Insufficient permissions
404 → Resource not found
409 → Conflict (duplicate, invalid state)
500 → Server error (logged, not exposed)
```

### **Error Recovery Patterns**
```
DATABASE RECONNECTION:
→ Exponential backoff on connection loss
→ Circuit breaker pattern
→ Graceful degradation

RATE LIMITING:
→ Token bucket algorithm
→ Per-IP and per-user limits
→ Headers: X-RateLimit-Limit, X-RateLimit-Remaining
```

## **8. Performance Optimization**

### **Database Optimization**
```
INDEXING STRATEGY:
→ Index fields in WHERE, ORDER BY, JOIN
→ Compound indexes for common query patterns
→ Regular index analysis with $indexStats

QUERY OPTIMIZATION:
→ Use projection to return only needed fields
→ Implement pagination with skip/limit
→ Use lean() for read-only operations
→ Batch operations where possible
```

### **Caching Strategy**
```
CACHE LAYERS:
L1: In-memory (frequently accessed user data)
L2: Redis (session data, token blacklist)
L3: Database (persistent storage)

CACHE INVALIDATION:
→ Write-through for critical data
→ Time-based expiration for static data
→ Manual invalidation on data change
```

## **9. Security Patterns**

### **Password Security Algorithm**
```
PASSWORD HANDLING:
→ Minimum 12 characters (with complexity)
→ bcrypt with cost factor 12
→ Never log or expose password
→ One-way hashing only

SECURITY HEADERS:
→ HSTS for HTTPS enforcement
→ CSP for XSS protection
→ X-Frame-Options for clickjacking
→ SameSite cookies for CSRF
```

### **Rate Limiting Algorithm**
```
TOKEN BUCKET IMPLEMENTATION:
→ Each user/IP gets token bucket
→ Tokens replenish over time
→ Requests consume tokens
→ 429 Too Many Requests when empty

DISTRIBUTED RATE LIMITING:
→ Use Redis for shared token state
→ Consistent across multiple servers
→ Configurable per endpoint
```

## **10. Deployment & Monitoring**

### **Health Check Endpoints**
```
HEALTH CHECK HIERARCHY:
/health → Basic server status
/health/db → Database connectivity
/health/redis → Redis connectivity
/health/storage → Disk space check

METRICS COLLECTION:
→ Request duration histogram
→ Error rate tracking
→ Database query performance
→ Memory usage monitoring
```

### **Logging Strategy**
```
STRUCTURED LOGGING FORMAT:
{
  timestamp: ISO string,
  level: 'info' | 'error' | 'warn',
  message: 'User registered',
  userId: 'abc123',
  requestId: 'req-xyz',
  duration: 150, // ms
  path: '/api/auth/register'
}

LOG LEVELS:
Error → System failures, security issues
Warn → Unusual but handled situations
Info → Normal operational messages
Debug → Detailed debugging information
```

## **Quick Reference: Mental Models**

### **Test-Driven Mindset**
```
RED-GREEN-REFACTOR CYCLE:
RED: Write test, watch it fail
GREEN: Write minimal code to pass
REFACTOR: Improve code, tests still pass

3 LAWS OF TDD:
1. Write no production code except to pass a failing test
2. Write only enough test to fail (compilation is failing)
3. Write only enough production code to pass the test
```

### **Authentication Flow Diagram**
```
[Client] → [Register/Login] → [Generate Token] → [Store Cookie]
     ↓           ↓                  ↓               ↓
  [Request] → [Auth Middleware] → [Verify Token] → [Check Blacklist]
     ↓           ↓                  ↓               ↓
  [Access]  ← [Attach User]   ← [Valid Token]  ← [Not Blacklisted]
```

### **Error Flow Diagram**
```
[Request] → [Validation] → [Auth] → [Business Logic] → [Database]
     ↓           ↓           ↓           ↓               ↓
  [400]      [400/401]   [401/403]    [409/404]      [500/503]
     ↓           ↓           ↓           ↓               ↓
[Client Error] ←←←←←←←←← [Standard Error Response] → [Log + Alert]
```

## **Pro Tips & Common Pitfalls**

### **Time-Saving Patterns**
```
TEST DATA CLEANUP:
→ Use database transactions where supported
→ Tag tests with cleanup requirements
→ Implement global test teardown

MOCK STRATEGY:
→ Mock at the lowest possible level
→ Use dependency injection for testability
→ Keep mock implementations simple
```

### **Performance Pitfalls**
```
COMMON BOTTLENECKS:
→ N+1 query problem (solve with population)
→ Large response payloads (implement pagination)
→ Synchronous operations in async context
→ Missing database indexes

OPTIMIZATION CHECKLIST:
✓ Index on frequently queried fields
✓ Implement response caching
✓ Use streaming for large datasets
✓ Batch database operations
```

### **Security Checklist**
```
ESSENTIAL SECURITY MEASURES:
✓ Password hashing (bcrypt/scrypt)
✓ HTTPS enforcement (HSTS)
✓ CSRF protection (SameSite cookies)
✓ Input validation and sanitization
✓ Rate limiting on auth endpoints
✓ Token blacklisting on logout
✓ Principle of least privilege
```

This algorithmic approach ensures a robust, testable, and maintainable authentication system that follows TDD principles while maintaining security and performance best practices.